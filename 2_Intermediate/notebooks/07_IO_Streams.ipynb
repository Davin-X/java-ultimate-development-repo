{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O Streams Mastery\n",
    "\n",
    "**Level 2: Intermediate - Advanced Stream Operations & Performance**\n",
    "\n",
    "**Master enterprise-grade stream processing, character encoding, and high-performance I/O patterns**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Hierarchy & Architecture\n",
    "\n",
    "**Understanding Java's powerful stream-based I/O system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Comprehensive stream hierarchy and enterprise I/O patterns\n",
    "import java.io.*;\n",
    "import java.nio.*;\n",
    "import java.nio.charset.*;\n",
    "import java.nio.file.*;\n",
    "import java.util.*;\n",
    "import java.util.zip.*;\n",
    "import java.util.function.*;\n",
    "\n",
    "public class StreamHierarchyMastery {\n",
    "\n",
    "    public static void demonstrateStreamHierarchy() {\n",
    "        System.out.println(\"=== JAVA I/O STREAM HIERARCHY MASTER ===\\n\");\n",
    "\n",
    "        System.out.println(\"üéØ STREAM ARCHITECTURE OVERVIEW:\");\n",
    "        System.out.println(\"‚Ä¢ InputStream/OutputStream: Byte-oriented I/O\");\n",
    "        System.out.println(\"‚Ä¢ Reader/Writer: Character-oriented I/O\");\n",
    "        System.out.println(\"‚Ä¢ Filter streams: Enhanced functionality\");\n",
    "        System.out.println(\"‚Ä¢ Data streams: Primitive type I/O\");\n",
    "        System.out.println(\"‚Ä¢ Object streams: Complete object serialization\");\n",
    "        System.out.println(\"‚Ä¢ Buffered streams: Performance optimization\\n\");\n",
    "\n",
    "        demonstrateByteVsCharacterStreams();\n",
    "        demonstrateFilterStreams();\n",
    "        demonstrateDataStreams();\n",
    "    }\n",
    "\n",
    "    public static void demonstrateByteVsCharacterStreams() {\n",
    "        System.out.println(\"=== BYTE vs CHARACTER STREAMS ===\\n\");\n",
    "\n",
    "        String content = \"Hello World! ‰Ω†Â•Ω‰∏ñÁïå üåü \" +\n",
    "                        \"Special chars: √†√°√¢√£√§√• √¶√ß√®√©√™√´ √±\";\n",
    "        Path testFile = Paths.get(\"stream_comparison.txt\");\n",
    "\n",
    "        try {\n",
    "            System.out.println(\"Original content: \" + content);\n",
    "            System.out.println(\"Length: \" + content.length() + \" characters\\n\");\n",
    "\n",
    "            // BYTE STREAM EXAMPLE (FileOutputStream)\n",
    "            try (FileOutputStream fos = new FileOutputStream(testFile.toFile())) {\n",
    "                byte[] bytes = content.getBytes(StandardCharsets.UTF_8);\n",
    "                fos.write(bytes);\n",
    "                System.out.println(\"‚úÖ Byte stream: Wrote \" + bytes.length + \" bytes\");\n",
    "            }\n",
    "\n",
    "            // CHARACTER STREAM EXAMPLE (FileWriter)\n",
    "            Path charFile = Paths.get(\"character_stream.txt\");\n",
    "\n",
    "            try (FileWriter fw = new FileWriter(charFile.toFile(), StandardCharsets.UTF_8)) {\n",
    "                fw.write(content);\n",
    "                System.out.println(\"‚úÖ Character stream: Wrote content directly\\n\");\n",
    "            }\n",
    "\n",
    "            // Reading comparison\n",
    "            System.out.println(\"Reading files back:\");\n",
    "\n",
    "            // Byte stream reading\n",
    "            try (FileInputStream fis = new FileInputStream(testFile.toFile())) {\n",
    "                byte[] buffer = new byte[1024];\n",
    "                int bytesRead = fis.read(buffer);\n",
    "                String fromBytes = new String(buffer, 0, bytesRead, StandardCharsets.UTF_8);\n",
    "                System.out.println(\"Byte stream read: \" + fromBytes);\n",
    "            }\n",
    "\n",
    "            // Character stream reading\n",
    "            try (FileReader fr = new FileReader(charFile.toFile(), StandardCharsets.UTF_8)) {\n",
    "                char[] charBuffer = new char[1024];\n",
    "                int charsRead = fr.read(charBuffer);\n",
    "                String fromChars = new String(charBuffer, 0, charsRead);\n",
    "                System.out.println(\"Character stream read: \" + fromChars);\n",
    "                System.out.println(\"‚úÖ Both preserve Unicode characters correctly\\n\");\n",
    "            }\n",
    "\n",
    "            // Cleanup\n",
    "            Files.deleteIfExists(testFile);\n",
    "            Files.deleteIfExists(charFile);\n",
    "\n",
    "        } catch (IOException e) {\n",
    "            System.out.println(\"‚ùå Stream comparison error: \" + e.getMessage());\n",
    "        }\n",
    "\n",
    "        System.out.println(\"üéØ WHEN TO USE EACH TYPE:\");\n",
    "        System.out.println(\"Byte Streams: Binary data, images, audio, custom protocols\");\n",
    "        System.out.println(\"Character Streams: Text files, configuration, human-readable data\");\n",
    "    }\n",
    "\n",
    "    public static void demonstrateFilterStreams() {\n",
    "        System.out.println(\"\\n=== FILTER STREAMS - ENHANCED FUNCTIONALITY ===\\n\");\n",
    "\n",
    "        Path originalFile = Paths.get(\"large_data.txt\");\n",
    "        Path compressedFile = Paths.get(\"large_data.txt.gz\");\n",
    "\n",
    "        try {\n",
    "            // Create test data\n",
    "            StringBuilder largeContent = new StringBuilder();\n",
    "            for (int i = 0; i < 1000; i++) {\n",
    "                largeContent.append(\"Line \").append(i).append(\": \")\n",
    "                           .append(\"This is a test line with some repetitive content. \")\n",
    "                           .append(\"We can compress this to save space!\\n\");\n",
    "            }\n",
    "\n",
    "            long originalSize = largeContent.length();\n",
    "            System.out.println(\"Original content size: \" + originalSize + \" characters\\n\");\n",
    "\n",
    "            // Demonstrate BufferedWriter for performance\n",
    "            long startTime = System.nanoTime();\n",
    "            try (BufferedWriter bw = new BufferedWriter(new FileWriter(originalFile.toFile()))) {\n",
    "                bw.write(largeContent.toString());\n",
    "                System.out.println(\"‚úÖ Written with BufferedWriter (performance optimized)\");\n",
    "            }\n",
    "\n",
    "            long writeTime = (System.nanoTime() - startTime) / 1_000_000;\n",
    "            System.out.println(\"Write time: \" + writeTime + \" ms\\n\");\n",
    "\n",
    "            // Demonstrate compression with GZIPOutputStream (filter stream)\n",
    "            startTime = System.nanoTime();\n",
    "            try (FileInputStream fis = new FileInputStream(originalFile.toFile());\n",
    "                 GZIPOutputStream gzos = new GZIPOutputStream(new FileOutputStream(compressedFile.toFile()))) {\n",
    "\n",
    "                byte[] buffer = new byte[8192];\n",
    "                int bytesRead;\n",
    "                while ((bytesRead = fis.read(buffer)) != -1) {\n",
    "                    gzos.write(buffer, 0, bytesRead);\n",
    "                }\n",
    "                System.out.println(\"‚úÖ Compressed with GZIPOutputStream (filter stream)\");\n",
    "            }\n",
    "\n",
    "            long compressionTime = (System.nanoTime() - startTime) / 1_000_000;\n",
    "            long compressedSize = Files.size(compressedFile);\n",
    "\n",
    "            System.out.println(\"Compression time: \" + compressionTime + \" ms\");\n",
    "            System.out.println(\"Compressed size: \" + compressedSize + \" bytes\");\n",
    "            System.out.println(\"Compression ratio: \" +\n",
    "                              String.format(\"%.1fx\", (double)originalSize / compressedSize));\n",
    "\n",
    "            // Decompress and verify\n",
    "            try (GZIPInputStream gzis = new GZIPInputStream(new FileInputStream(compressedFile.toFile())); \n",
    "                 ByteArrayOutputStream baos = new ByteArrayOutputStream()) {\n",
    "                \n",
    "                byte[] buffer = new byte[8192];\n",
    "                int bytesRead;\n",
    "                while ((bytesRead = gzis.read(buffer)) != -1) {\n",
    "                    baos.write(buffer, 0, bytesRead);\n",
    "                }\n",
    "                \n",
    "                String decompressed = baos.toString(\"UTF-8\");\n",
    "                boolean dataIntegrity = decompressed.equals(largeContent.toString());\n",
    "                System.out.println(\"‚úÖ Decompression successful, data integrity: \" + dataIntegrity);\n",
    "            }\n",
    "\n",
    "            // Cleanup\n",
    "            Files.deleteIfExists(originalFile);\n",
    "            Files.deleteIfExists(compressedFile);\n",
    "\n",
    "        } catch (IOException e) {\n",
    "            System.out.println(\"‚ùå Filter streams demonstration error: \" + e.getMessage());\n",
    "        }\n",
    "\n",
    "        System.out.println(\"\\nüéØ FILTER STREAMS BENEFITS:\");\n",
    "        System.out.println(\"‚Ä¢ Add functionality to existing streams (buffering, compression)\");\n",
    "        System.out.println(\"‚Ä¢ Can be chained together for complex operations\");\n",
    "        System.out.println(\"‚Ä¢ Separate concerns (buffering vs compression vs encoding)\");\n",
    "        System.out.println(\"‚Ä¢ Performance optimization through decoration pattern\");\n",
    "    }\n",
    "\n",
    "    public static void demonstrateDataStreams() {\n",
    "        System.out.println(\"\\n=== DATA STREAMS - CROSS-PLATFORM PRIMITIVE I/O ===\\n\");\n",
    "\n",
    "        Path dataFile = Paths.get(\"primitive_data.bin\");\n",
    "\n",
    "        try (DataOutputStream dos = new DataOutputStream(new FileOutputStream(dataFile.toFile()))) {\n",
    "            \n",
    "            System.out.println(\"Writing mixed data types with DataOutputStream:\");\n",
    "            \n",
    "            dos.writeBoolean(true);\n",
    "            dos.writeByte(42);\n",
    "            dos.writeChar('A');\n",
    "            dos.writeShort((short) 1000);\n",
    "            dos.writeInt(123456);\n",
    "            dos.writeLong(9876543210L);\n",
    "            dos.writeFloat(3.14159f);\n",
    "            dos.writeDouble(Math.PI);\n",
    "            dos.writeUTF(\"Data streams preserve exact values!\");\n",
    "            \n",
    "            System.out.println(\"‚úÖ All primitive types written in binary format\");\n",
    "            \n",
    "        } catch (IOException e) {\n",
    "            System.out.println(\"‚ùå DataOutputStream error: \" + e.getMessage());\n",
    "            return;\n",
    "        }\n",
    "\n",
    "        try (DataInputStream dis = new DataInputStream(new FileInputStream(dataFile.toFile()))) {\n",
    "            \n",
    "            System.out.println(\"\\nReading data back with exact precision:\");\n",
    "            \n",
    "            boolean boolVal = dis.readBoolean();\n",
    "            byte byteVal = dis.readByte();\n",
    "            char charVal = dis.readChar();\n",
    "            short shortVal = dis.readShort();\n",
    "            int intVal = dis.readInt();\n",
    "            long longVal = dis.readLong();\n",
    "            float floatVal = dis.readFloat();\n",
    "            double doubleVal = dis.readDouble();\n",
    "            String stringVal = dis.readUTF();\n",
    "            \n",
    "            System.out.printf(\"Boolean: %-5s | Byte: %-3d | Char: %-3c | Short: %-5d\\n\",\n",
    "                             boolVal, byteVal, charVal, shortVal);\n",
    "            System.out.printf(\"Int: %-8d | Long: %-12d | Float: %-8.5f | Double: %.10f\\n\",\n",
    "                             intVal, longVal, floatVal, doubleVal);\n",
    "            System.out.println(\"String: \" + stringVal);\n",
    "            \n",
    "            System.out.println(\"\\n‚úÖ All values read back with perfect precision!\");\n",
    "            \n",
    "        } catch (IOException e) {\n",
    "            System.out.println(\"‚ùå DataInputStream error: \" + e.getMessage());\n",
    "        }\n",
    "\n",
    "        // Cleanup\n",
    "        try {\n",
    "            Files.deleteIfExists(dataFile);\n",
    "        } catch (IOException e) {\n",
    "            System.out.println(\"Could not clean up data file\");\n",
    "        }\n",
    "\n",
    "        System.out.println(\"\\nüéØ DATA STREAMS ADVANTAGES:\");\n",
    "        System.out.println(\"‚Ä¢ Cross-platform binary format (big-endian)\");\n",
    "        System.out.println(\"‚Ä¢ Preserves exact primitive values\");\n",
    "        System.out.println(\"‚Ä¢ Compact representation for numeric data\");\n",
    "        System.out.println(\"‚Ä¢ Platform-independent serialization\");\n",
    "        System.out.println(\"‚Ä¢ Perfect for game saves, configuration, scientific data\");\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        demonstrateStreamHierarchy();\n",
    "        \n",
    "        System.out.println(\"\\nüéØ I/O STREAM HIERARCHY MASTERY:\");\n",
    "        System.out.println(\"‚Ä¢ Byte vs Character streams for appropriate data types\");\n",
    "        System.out.println(\"‚Ä¢ Filter streams for enhanced functionality (buffering, compression)\");\n",
    "        System.out.println(\"‚Ä¢ Data streams for cross-platform primitive I/O\");\n",
    "        System.out.println(\"‚Ä¢ Stream chaining for complex I/O operations\");\n",
    "        System.out.println(\"‚Ä¢ Performance optimization through appropriate buffer sizes\");\n",
    "        \n",
    "        System.out.println(\"\\nThis hierarchy powers all Java I/O operations!\");\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Stream Processing\n",
    "\n",
    "**Enterprise patterns for bulk data processing and performance optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Advanced stream processing patterns for enterprise applications\n",
    "import java.io.*;\n",
    "import java.nio.*;\n",
    "import java.nio.channels.*;\n",
    "import java.nio.file.*;\n",
    "import java.util.*;\n",
    "import java.util.concurrent.*;\n",
    "import java.util.stream.*;\n",
    "import java.util.function.*;\n",
    "\n",
    "public class AdvancedStreamProcessing {\n",
    "\n",
    "    public static void demonstrateBulkDataProcessing() {\n",
    "        System.out.println(\"=== BULK DATA PROCESSING PATTERNS ===\\n\");\n",
    "\n",
    "        Path sourceFile = Paths.get(\"large_dataset.dat\");\n",
    "        Path processedFile = Paths.get(\"processed_data.txt\");\n",
    "\n",
    "        try {\n",
    "            // Generate large test dataset\n",
    "            try (DataOutputStream dos = new DataOutputStream(new BufferedOutputStream(\n",
    "                    new FileOutputStream(sourceFile.toFile())))) {\n",
    "\n",
    "                for (int i = 0; i < 100_000; i++) {\n",
    "                    dos.writeInt(i);                    // Record ID\n",
    "                    dos.writeDouble(Math.random());    // Data value\n",
    "                    dos.writeUTF(\"Record_\" + i);       // Description\n",
    "                }\n",
    "                System.out.println(\"‚úÖ Generated test dataset: 100,000 records\");\n",
    "            }\n",
    "\n",
    "            // Process bulk data efficiently\n",
    "            long startTime = System.nanoTime();\n",
    "            try (DataInputStream dis = new DataInputStream(new BufferedInputStream(\n",
    "                        new FileInputStream(sourceFile.toFile())));\n",
    "                 PrintWriter pw = new PrintWriter(new BufferedWriter(\n",
    "                        new FileWriter(processedFile.toFile())))) {\n",
    "\n",
    "                pw.println(\"ID\\tValue\\tDescription\\tCategory\");\n",
    "                pw.println(\"=====================================\");\n",
    "\n",
    "                int recordsProcessed = 0;\n",
    "                double totalValue = 0;\n",
    "\n",
    "                while (dis.available() > 0) {\n",
    "                    int id = dis.readInt();\n",
    "                    double value = dis.readDouble();\n",
    "                    String desc = dis.readUTF();\n",
    "\n",
    "                    // Process data\n",
    "                    String category = categorizeValue(value);\n",
    "                    totalValue += value;\n",
    "                    recordsProcessed++;\n",
    "\n",
    "                    // Write processed record\n",
    "                    pw.printf(\"%d\\t%.4f\\t%s\\t%s\\n\", id, value, desc, category);\n",
    "                }\n",
    "\n",
    "                pw.println(\"=====================================\");\n",
    "                pw.printf(\"Records: %d, Average: %.4f\\n\", recordsProcessed, totalValue / recordsProcessed);\n",
    "\n",
    "                long processingTime = (System.nanoTime() - startTime) / 1_000_000;\n",
    "                System.out.println(\"\\n‚úÖ Bulk processing completed:\");\n",
    "                System.out.println(\"‚Ä¢ Processed \" + recordsProcessed + \" records\");\n",
    "                System.out.println(\"‚Ä¢ Average value: \" + String.format(\"%.4f\", totalValue / recordsProcessed));\n",
    "                System.out.println(\"‚Ä¢ Processing time: \" + processingTime + \" ms\");\n",
    "                System.out.println(\"‚Ä¢ Throughput: \" + (recordsProcessed / (processingTime / 1000.0)) + \" records/sec\");\n",
    "            }\n",
    "\n",
    "            // Verify file sizes\n",
    "            long sourceSize = Files.size(sourceFile);\n",
    "            long processedSize = Files.size(processedFile);\n",
    "            System.out.println(\"\\nFile sizes: Source=\" + sourceSize + \" bytes, Processed=\" + processedSize + \" bytes\");\n",
    "\n",
    "            // Cleanup\n",
    "            Files.deleteIfExists(sourceFile);\n",
    "            Files.deleteIfExists(processedFile);\n",
    "\n",
    "        } catch (IOException e) {\n",
    "            System.out.println(\"‚ùå Bulk processing error: \" + e.getMessage());\n",
    "        }\n",
    "\n",
    "        System.out.println(\"\\nüéØ BULK PROCESSING BEST PRACTICES:\");\n",
    "        System.out.println(\"‚Ä¢ Use BufferedInputStream/BufferedOutputStream\");\n",
    "        System.out.println(\"‚Ä¢ Process data in chunks to avoid memory issues\");\n",
    "        System.out.println(\"‚Ä¢ Chain streams appropriately (DataOutputStream over BufferedOutputStream)\");\n",
    "        System.out.println(\"‚Ä¢ Close streams in reverse order of creation\");\n",
    "        System.out.println(\"‚Ä¢ Monitor I/O performance and adjust buffer sizes\");\n",
    "    }\n",
    "\n",
    "    private static String categorizeValue(double value) {\n",
    "        if (value < 0.3) return \"Low\";\n",
    "        else if (value < 0.7) return \"Medium\";\n",
    "        else return \"High\";\n",
    "    }\n",
    "\n",
    "    public static void demonstrateStreamPerformance() {\n",
    "        System.out.println(\"\\n=== STREAM PERFORMANCE OPTIMIZATION ===\\n\");\n",
    "\n",
    "        Path testFile = Paths.get(\"performance_test.txt\");\n",
    "        String testData = \"This is a test line for performance comparison. \" +\n",
    "                         \"We repeat this line many times to measure I/O performance.\\n\";\n",
    "\n",
    "        try {\n",
    "            // Create large file for testing\n",
    "            try (BufferedWriter bw = new BufferedWriter(new FileWriter(testFile.toFile()))) {\n",
    "                for (int i = 0; i < 50_000; i++) {\n",
    "                    bw.write(testData);\n",
    "                }\n",
    "            }\n",
    "\n",
    "            long fileSize = Files.size(testFile);\n",
    "            System.out.println(\"Created test file: \" + fileSize + \" bytes\\n\");\n",
    "\n",
    "            // Test different reading approaches\n",
    "            double[] readSpeeds = new double[4];\n",
    "            String[] approaches = {\n",
    "                \"FileInputStream (unbuffered)\",\n",
    "                \"BufferedInputStream\",\n",
    "                \"FileReader (unbuffered)\",\n",
    "                \"BufferedReader\"\n",
    "            };\n",
    "\n",
    "            // Approach 1: Unbuffered FileInputStream\n",
    "            readSpeeds[0] = measureReadSpeed(testFile, () -> {\n",
    "                try (FileInputStream fis = new FileInputStream(testFile.toFile())) {\n",
    "                    byte[] buffer = new byte[8192];\n",
    "                    while (fis.read(buffer) != -1) { /* Read and discard */ }\n",
    "                } catch (IOException e) {\n",
    "                    System.out.println(\"Error: \" + e.getMessage());\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Approach 2: BufferedInputStream\n",
    "            readSpeeds[1] = measureReadSpeed(testFile, () -> {\n",
    "                try (BufferedInputStream bis = new BufferedInputStream(\n",
    "                        new FileInputStream(testFile.toFile()))) {\n",
    "                    byte[] buffer = new byte[8192];\n",
    "                    while (bis.read(buffer) != -1) { /* Read and discard */ }\n",
    "                } catch (IOException e) {\n",
    "                    System.out.println(\"Error: \" + e.getMessage());\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Approach 3: FileReader (unbuffered)\n",
    "            readSpeeds[2] = measureReadSpeed(testFile, () -> {\n",
    "                try (FileReader fr = new FileReader(testFile.toFile())) {\n",
    "                    char[] buffer = new char[4096];\n",
    "                    while (fr.read(buffer) != -1) { /* Read and discard */ }\n",
    "                } catch (IOException e) {\n",
    "                    System.out.println(\"Error: \" + e.getMessage());\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Approach 4: BufferedReader\n",
    "            readSpeeds[3] = measureReadSpeed(testFile, () -> {\n",
    "                try (BufferedReader br = new BufferedReader(new FileReader(testFile.toFile()))) {\n",
    "                    char[] buffer = new char[4096];\n",
    "                    while (br.read(buffer) != -1) { /* Read and discard */ }\n",
    "                } catch (IOException e) {\n",
    "                    System.out.println(\"Error: \" + e.getMessage());\n",
    "                }\n",
    "            });\n",
    "\n",
    "            // Display results\n",
    "            System.out.println(\"READ PERFORMANCE COMPARISON:\");\n",
    "            System.out.println(\"================================\");\n",
    "            for (int i = 0; i < approaches.length; i++) {\n",
    "                System.out.printf(\"%-25s: %.2f MB/s\\n\", approaches[i], readSpeeds[i]);\n",
    "            }\n",
    "\n",
    "            double maxSpeed = Arrays.stream(readSpeeds).max().orElse(0);\n",
    "            int fastestIndex = 0;\n",
    "            for (int i = 0; i < readSpeeds.length; i++) {\n",
    "                if (readSpeeds[i] == maxSpeed) {\n",
    "                    fastestIndex = i;\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            System.out.println(\"\\nüéØ PERFORMANCE INSIGHTS:\");\n",
    "            System.out.println(\"‚Ä¢ Fastest: \" + approaches[fastestIndex]);\n",
    "            System.out.println(\"‚Ä¢ Buffering improves performance by \" +\n",
    "                             String.format(\"%.1fx\", readSpeeds[fastestIndex] / readSpeeds[fastestIndex % 2]));\n",
    "            System.out.println(\"‚Ä¢ Choose BufferedReader for text files, BufferedInputStream for binary\");\n",
    "\n",
    "            // Cleanup\n",
    "            Files.deleteIfExists(testFile);\n",
    "\n",
    "        } catch (IOException e) {\n",
    "            System.out.println(\"‚ùå Performance test error: \" + e.getMessage());\n",
    "        }\n",
    "    }\n",
    "\n",
    "    private static double measureReadSpeed(Path file, Runnable readTask) {\n",
    "        long startTime = System.nanoTime();\n",
    "        readTask.run();\n",
    "        long endTime = System.nanoTime();\n",
    "\n",
    "        try {\n",
    "            long fileSize = Files.size(file);\n",
    "            double timeInSeconds = (endTime - startTime) / 1_000_000_000.0;\n",
    "            double speedMBPerSec = (fileSize / (1024.0 * 1024.0)) / timeInSeconds;\n",
    "            return speedMBPerSec;\n",
    "        } catch (IOException e) {\n",
    "            return 0.0;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public static void demonstrateConcurrentStreams() {\n",
    "        System.out.println(\"\\n=== CONCURRENT STREAM PROCESSING ===\\n\");\n",
    "\n",
    "        Path concurrentTestFile = Paths.get(\"concurrent_data.txt\");\n",
    "\n",
    "        try {\n",
    "            // Generate test data\n",
    "            try (PrintWriter pw = new PrintWriter(new BufferedWriter(\n",
    "                    new FileWriter(concurrentTestFile.toFile())))) {\n",
    "\n",
    "                for (int i = 0; i < 1_000_000; i++) {\n",
    "                    pw.println(\"Record_\" + i + \",\" + Math.random());\n",
    "                }\n",
    "                System.out.println(\"‚úÖ Created test dataset: 1,000,000 records\");\n",
    "            }\n",
    "\n",
    "            // Process concurrently using parallel streams\n",
    "            long startTime = System.nanoTime();\n",
    "\n",
    "            try (Stream<String> lines = Files.lines(concurrentTestFile)) {\n",
    "                Map<String, Double> results = lines\n",
    "                    .parallel()\n",
    "                    .map(line -> line.split(\",\"))\n",
    "                    .filter(parts -> parts.length == 2)\n",
    "                    .map(parts -> {\n",
    "                        try {\n",
    "                            return Double.parseDouble(parts[1]);\n",
    "                        } catch (NumberFormatException e) {\n",
    "                            return 0.0;\n",
    "                        }\n",
    "                    })\n",
    "                    .collect(Collectors.groupingBy(\n",
    "                        value -> {\n",
    "                            if (value < 0.3) return \"Low\";\n",
    "                            else if (value < 0.7) return \"Medium\";\n",
    "                            else return \"High\";\n",
    "                        },\n",
    "                        Collectors.summingDouble(Double::doubleValue)\n",
    "                    ));\n",
    "\n",
    "                long processingTime = (System.nanoTime() - startTime) / 1_000_000;\n",
    "\n",
    "                System.out.println(\"\\n‚úÖ Concurrent processing completed in \" + processingTime + \" ms\");\n",
    "                System.out.println(\"Results: \" + results);\n",
    "                System.out.println(\"Sum by category:\");\n",
    "                results.forEach((category, sum) ->\n",
    "                    System.out.println(\"  \" + category + \": \" + String.format(\"%.2f\", sum)));\n",
    "            }\n",
    "\n",
    "            System.out.println(\"\\nüéØ CONCURRENT STREAM ADVANTAGES:\");\n",
    "            System.out.println(\"‚Ä¢ Automatic parallelization for CPU-intensive operations\");\n",
    "            System.out.println(\"‚Ä¢ Declarative programming style (what, not how)\");\n",
    "            System.out.println(\"‚Ä¢ Efficient memory usage with lazy evaluation\");\n",
    "            System.out.println(\"‚Ä¢ Perfect for large dataset processing and transformation\");\n",
    "\n",
    "            // Cleanup\n",
    "            Files.deleteIfExists(concurrentTestFile);\n",
    "\n",
    "        } catch (IOException e) {\n",
    "            System.out.println(\"‚ùå Concurrent streams error: \" + e.getMessage());\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        demonstrateBulkDataProcessing();\n",
    "        demonstrateStreamPerformance();\n",
    "        demonstrateConcurrentStreams();\n",
    "\n",
    "        System.out.println(\"\\nüéØ ADVANCED STREAM PROCESSING MASTERED:\");\n",
    "        System.out.println(\"‚Ä¢ Bulk data processing with proper buffering and performance monitoring\");\n",
    "        System.out.println(\"‚Ä¢ Stream performance optimization and benchmarking techniques\");\n",
    "        System.out.println(\"‚Ä¢ Concurrent stream processing for massive datasets\");\n",
    "        System.out.println(\"‚Ä¢ Choosing appropriate stream types for different use cases\");\n",
    "        System.out.println(\"‚Ä¢ Memory-efficient processing of large files\");\n",
    "        \n",
    "        System.out.println(\"\\nEnterprise applications rely on these patterns for scalable I/O operations!\");\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "name": "java",
   "version": "17.0.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
